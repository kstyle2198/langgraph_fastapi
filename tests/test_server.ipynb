{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\langgraph_fastapi_streamlit'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv()) # important line if cannot load api key\n",
    "\n",
    "import os\n",
    "# os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "# os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "\n",
    "# WebSearch tools\n",
    "# os.environ['SERPAPI_API_KEY'] = os.getenv('SERPAPI_API_KEY')\n",
    "# os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')\n",
    "# os.environ['GOOGLE_CSE_ID'] = os.getenv('GOOGLE_CSE_ID')\n",
    "# os.environ['TAVILY_API_KEY'] = os.getenv('TAVILY_API_KEY')\n",
    "\n",
    "# Langsmith Tracing\n",
    "# os.environ['LANGCHAIN_TRACING_V2'] = os.getenv('LANGCHAIN_TRACING_V2')\n",
    "# os.environ['LANGCHAIN_ENDPOINT'] = os.getenv('LANGCHAIN_ENDPOINT')\n",
    "# os.environ['LANGCHAIN_PROJECT'] = os.getenv('LANGCHAIN_PROJECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_chroma.vectorstores.Chroma at 0x2172caf3950>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "embedding_model = OllamaEmbeddings(base_url=\"http://localhost:11434\", model=\"bge-m3:latest\")\n",
    "store = Chroma(collection_name=\"collection_01\", persist_directory=\"../db/chroma_db_02\", embedding_function=embedding_model)\n",
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OllamaEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x000002172CAF3950>, search_kwargs={})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = store.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='28d09004-1c9a-4ead-b09a-4f95c6be933f', metadata={'File Name': 'Focus on IMO - SOLAS, the International Convention for the Safety, of Life at Sea, 1974 (October 1998)', 'File Path': '/content/drive/MyDrive/Rules/SOLAS/Focus on IMO - SOLAS, the International Convention for the Safety, of Life at Sea, 1974 (October 1998).pdf', 'First Division': 'Rules', 'Page': 14, 'Second Division': 'SOLAS'}, page_content='This page explains Focus on IMO - SOLAS, the International Convention for the Safety, of Life at Sea, 1974 (October 1998), that belongs to catogories of Rules and SOLAS./nfor safe practices in ship operation and a safe working environment;  • to establish safeguards against all identified risks;  • to continuously improve safety management skills of personnel, including preparing for emergencies.  The Code requires a safety management system (SMS) to be established by \"the Company\", which is defined as the shipowner or any person, such as the manager or bareboat charterer, who has assumed responsibility for operating the ship. This system should be designed to ensure compliance with all mandatory regulations and that codes, guidelines and standards recommended by IMO and others are taken into account.  The SMS in turn should include a number of functional requirements:'),\n",
       " Document(id='84d8c8c1-0467-41dd-a89f-0faf7124bbe6', metadata={'File Name': '370_RULES FOR THE AUDIT AND REGISTRATION OF SHIP SECURITY MANAGEMENT SYSTEMS_202406', 'File Path': '/content/drive/MyDrive/Rules/NK/370_RULES FOR THE AUDIT AND REGISTRATION OF SHIP SECURITY MANAGEMENT SYSTEMS_202406.pdf', 'First Division': 'Rules', 'Page': 1, 'Second Division': 'NK'}, page_content='This page explains 370_RULES FOR THE AUDIT AND REGISTRATION OF SHIP SECURITY MANAGEMENT SYSTEMS_202406, that belongs to catogories of Rules and NK./nmanagement system may be deemed to comply with the Rules.  1.1.3 Definitions *  For the purposes of the Rules, the following definitions apply unless otherwise provided for:  (1) SOLAS means the International Convention for the Safety of Life at Sea, 1974 as amended . (2) ISPS Code means the International Code for the Security for Ships and Port Facilities adopted on 12 December 2002, by Resolution 2 of the Conference of Contracting Governments to SOLAS . (3) Ship security requirements which are deemed necessary by the Society refer to the following:  (a) Regulation 4, 5 and 8, Chapter XI -2 of SOLAS  (b) Section 5 through 13 of the ISPS Code Part A  (c) Section 8 through 13 of the ISPS Code Part B  (4) “Ship security management system” means a system built up to ensure the effective implementation and maintenance of the ship security plan.  (5) “Ship security plan” means a documented plan developed to ensure the application of measures on board the ship designed to protect persons on'),\n",
       " Document(id='88dd5fd8-c79c-422c-8244-d6731072409f', metadata={'File Name': 'Focus on IMO - SOLAS, the International Convention for the Safety, of Life at Sea, 1974 (October 1998)', 'File Path': '/content/drive/MyDrive/Rules/SOLAS/Focus on IMO - SOLAS, the International Convention for the Safety, of Life at Sea, 1974 (October 1998).pdf', 'First Division': 'Rules', 'Page': 8, 'Second Division': 'SOLAS'}, page_content='This page explains Focus on IMO - SOLAS, the International Convention for the Safety, of Life at Sea, 1974 (October 1998), that belongs to catogories of Rules and SOLAS./nmany of which were based on the findings of the inquiry into the disaster, were presented to IMO in separate packages, the first of which was adopted by the MSC in April 1988.  The amendments involve the addition of new regulations 23 -2 and 42 -1 to Chapter II -1 of the SOLAS Convention. Regulation 23 -2 deals with the integrity of the hull and superstructure, damage prevention and control and requires that indicators be provided on the navigatin g bridge for all doors which, if left open, could lead to major flooding of a special category space or a ro -ro cargo space.  The same regulation also requires that means be arranged, such as television surveillance or a water leakage detection system, to p rovide an indication to the navigating bridge of any leakage through doors which could lead to major flooding. Existing ships could be exempted from this requirement for a period of three years after the entry into force of the amendments (i.e. until 22 O ctober 1992).  Special category'),\n",
       " Document(id='4721708e-16e0-47df-a2e7-2c776ed76c8a', metadata={'File Name': 'Focus on IMO - SOLAS, the International Convention for the Safety, of Life at Sea, 1974 (October 1998)', 'File Path': '/content/drive/MyDrive/Rules/SOLAS/Focus on IMO - SOLAS, the International Convention for the Safety, of Life at Sea, 1974 (October 1998).pdf', 'First Division': 'Rules', 'Page': 3, 'Second Division': 'SOLAS'}, page_content='This page explains Focus on IMO - SOLAS, the International Convention for the Safety, of Life at Sea, 1974 (October 1998), that belongs to catogories of Rules and SOLAS./n4 Contracting Governments or by Contracting Governments whose combined merchant fleets represent not less than 50 per cent of world gross tonnage.  The article contains other provisions for entry into force of amendments incl uding the explicit acceptance procedure but in practice the tacit acceptance procedure described above proves the most rapid and effective way of securing the entry into force of amendments to the technical annex (other than Chapter I) and is now invariabl y used.   The Annex  Chapter I: General provisions  The most important of these concern the surveys required for various types of ships and the issuing of documents signifying that ships meet the requirements of the Convention.  The survey requirements for pas senger ships include a survey before the ship is put into service; a periodical survey (in most cases once every 12 months) and additional surveys as the occasion arises. In the case of cargo ships, after the initial survey, the ship is subject to a')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test it!\n",
    "query = \"let me know brief explanation about SOLAS?\"\n",
    "docs = retriever.invoke(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_search(query:str, db_path:str):\n",
    "    embed_model = OllamaEmbeddings(base_url=\"http://localhost:11434\", model=\"bge-m3:latest\")\n",
    "    vector_store = Chroma(collection_name=\"collection_01\", persist_directory=db_path, embedding_function=embed_model)\n",
    "    results = vector_store.similarity_search_with_relevance_scores(query, k=3)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(id='28d09004-1c9a-4ead-b09a-4f95c6be933f', metadata={'File Name': 'Focus on IMO - SOLAS, the International Convention for the Safety, of Life at Sea, 1974 (October 1998)', 'File Path': '/content/drive/MyDrive/Rules/SOLAS/Focus on IMO - SOLAS, the International Convention for the Safety, of Life at Sea, 1974 (October 1998).pdf', 'First Division': 'Rules', 'Page': 14, 'Second Division': 'SOLAS'}, page_content='This page explains Focus on IMO - SOLAS, the International Convention for the Safety, of Life at Sea, 1974 (October 1998), that belongs to catogories of Rules and SOLAS./nfor safe practices in ship operation and a safe working environment;  • to establish safeguards against all identified risks;  • to continuously improve safety management skills of personnel, including preparing for emergencies.  The Code requires a safety management system (SMS) to be established by \"the Company\", which is defined as the shipowner or any person, such as the manager or bareboat charterer, who has assumed responsibility for operating the ship. This system should be designed to ensure compliance with all mandatory regulations and that codes, guidelines and standards recommended by IMO and others are taken into account.  The SMS in turn should include a number of functional requirements:'),\n",
       "  0.4984172258081574),\n",
       " (Document(id='84d8c8c1-0467-41dd-a89f-0faf7124bbe6', metadata={'File Name': '370_RULES FOR THE AUDIT AND REGISTRATION OF SHIP SECURITY MANAGEMENT SYSTEMS_202406', 'File Path': '/content/drive/MyDrive/Rules/NK/370_RULES FOR THE AUDIT AND REGISTRATION OF SHIP SECURITY MANAGEMENT SYSTEMS_202406.pdf', 'First Division': 'Rules', 'Page': 1, 'Second Division': 'NK'}, page_content='This page explains 370_RULES FOR THE AUDIT AND REGISTRATION OF SHIP SECURITY MANAGEMENT SYSTEMS_202406, that belongs to catogories of Rules and NK./nmanagement system may be deemed to comply with the Rules.  1.1.3 Definitions *  For the purposes of the Rules, the following definitions apply unless otherwise provided for:  (1) SOLAS means the International Convention for the Safety of Life at Sea, 1974 as amended . (2) ISPS Code means the International Code for the Security for Ships and Port Facilities adopted on 12 December 2002, by Resolution 2 of the Conference of Contracting Governments to SOLAS . (3) Ship security requirements which are deemed necessary by the Society refer to the following:  (a) Regulation 4, 5 and 8, Chapter XI -2 of SOLAS  (b) Section 5 through 13 of the ISPS Code Part A  (c) Section 8 through 13 of the ISPS Code Part B  (4) “Ship security management system” means a system built up to ensure the effective implementation and maintenance of the ship security plan.  (5) “Ship security plan” means a documented plan developed to ensure the application of measures on board the ship designed to protect persons on'),\n",
       "  0.46621821365759275),\n",
       " (Document(id='88dd5fd8-c79c-422c-8244-d6731072409f', metadata={'File Name': 'Focus on IMO - SOLAS, the International Convention for the Safety, of Life at Sea, 1974 (October 1998)', 'File Path': '/content/drive/MyDrive/Rules/SOLAS/Focus on IMO - SOLAS, the International Convention for the Safety, of Life at Sea, 1974 (October 1998).pdf', 'First Division': 'Rules', 'Page': 8, 'Second Division': 'SOLAS'}, page_content='This page explains Focus on IMO - SOLAS, the International Convention for the Safety, of Life at Sea, 1974 (October 1998), that belongs to catogories of Rules and SOLAS./nmany of which were based on the findings of the inquiry into the disaster, were presented to IMO in separate packages, the first of which was adopted by the MSC in April 1988.  The amendments involve the addition of new regulations 23 -2 and 42 -1 to Chapter II -1 of the SOLAS Convention. Regulation 23 -2 deals with the integrity of the hull and superstructure, damage prevention and control and requires that indicators be provided on the navigatin g bridge for all doors which, if left open, could lead to major flooding of a special category space or a ro -ro cargo space.  The same regulation also requires that means be arranged, such as television surveillance or a water leakage detection system, to p rovide an indication to the navigating bridge of any leakage through doors which could lead to major flooding. Existing ships could be exempted from this requirement for a period of three years after the entry into force of the amendments (i.e. until 22 O ctober 1992).  Special category'),\n",
       "  0.4564090825757128)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = similarity_search(query=query, db_path=\"../db/chroma_db_02\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langgraph.graph import END, StateGraph\n",
    "from fastapi import FastAPI\n",
    "from langserve import add_routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LLM model\n",
    "# llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "llm = ChatGroq(temperature=0, model_name= \"llama-3.2-3b-preview\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_chain.py\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def create_generate_chain(llm):\n",
    "    \"\"\"\n",
    "    Creates a generate chain for answering code-related questions.\n",
    "\n",
    "    Args:\n",
    "        llm (LLM): The language model to use for generating responses.\n",
    "\n",
    "    Returns:\n",
    "        A callable function that takes a context and a question as input and returns a string response.\n",
    "    \"\"\"\n",
    "\n",
    "    generate_template = \"\"\"\n",
    "    You are a smart AI assistant. \n",
    "    Use the following pieces of retrieved context to answer the question. \n",
    "    Generate detailed answer including specified numbers, fomulas in the point of technical specifications. \n",
    "    If you don't know the answer, just say that you don't know. Do NOT try to make up an answer.\n",
    "    If the question is not related to the context, politely respond that you only answer questions related to the context.\n",
    "\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "\n",
    "    <question>\n",
    "    {question}\n",
    "    </question>\n",
    "    \"\"\"\n",
    "\n",
    "    generate_prompt = PromptTemplate(template=generate_template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "    # Create the generate chain\n",
    "    generate_chain = generate_prompt | llm | StrOutputParser()\n",
    "\n",
    "    return generate_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"\\n    You are a smart AI assistant. \\n    Use the following pieces of retrieved context to answer the question. \\n    Generate detailed answer including specified numbers, fomulas in the point of technical specifications. \\n    If you don't know the answer, just say that you don't know. Do NOT try to make up an answer.\\n    If the question is not related to the context, politely respond that you only answer questions related to the context.\\n\\n    <context>\\n    {context}\\n    </context>\\n\\n    <question>\\n    {question}\\n    </question>\\n    \")\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002172E48E180>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002172E48EA20>, model_name='llama-3.2-3b-preview', temperature=1e-08, model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the generate chain\n",
    "generate_chain = create_generate_chain(llm)\n",
    "generate_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, SOLAS (International Convention for the Safety of Life at Sea, 1974) is a maritime convention that aims to ensure the safety of life at sea. The convention requires ships to be designed, constructed, and equipped to prevent accidents and minimize the risk of loss of life.\n",
      "\n",
      "According to the context, SOLAS has undergone several amendments, including the addition of new regulations 23-2 and 42-1 to Chapter II-1 of the SOLAS Convention. Regulation 23-2 deals with the integrity of the hull and superstructure, damage prevention, and control, and requires indicators to be provided on the navigating bridge for all doors that, if left open, could lead to major flooding.\n",
      "\n",
      "SOLAS also requires the establishment of a safety management system (SMS) by shipowners or operators, which should be designed to ensure compliance with all mandatory regulations and take into account codes, guidelines, and standards recommended by IMO and others.\n",
      "\n",
      "In summary, SOLAS is a maritime convention that aims to ensure the safety of life at sea by setting standards for ship design, construction, and operation, and requires the establishment of a safety management system to prevent accidents and minimize the risk of loss of life.\n"
     ]
    }
   ],
   "source": [
    "generation = generate_chain.invoke({\"context\": docs, \"question\": query})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain import hub\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class GraderUtils:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def create_retrieval_grader(self):\n",
    "        \"\"\"\n",
    "        Creates a retrieval grader that assesses the relevance of a retrieved document to a user question.\n",
    "\n",
    "        Returns:\n",
    "            A callable function that takes a document and a question as input and returns a JSON object with a binary score indicating whether the document is relevant to the question.\n",
    "        \"\"\"\n",
    "        grade_prompt = PromptTemplate(\n",
    "            template=\"\"\"\n",
    "            <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "            You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "            If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "            It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "            Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\n",
    "            Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
    "            <|eot_id|>\n",
    "            <|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "            Here is the retrieved document: \\n\\n {document} \\n\\n\n",
    "            Here is the user question: {question} \\n\n",
    "            <|eot_id|>\n",
    "            <|start_header_id|>assistant<|end_header_id|>\n",
    "            \"\"\",\n",
    "            input_variables=[\"document\", \"question\"],\n",
    "        )\n",
    "\n",
    "        # Create the retriever chain\n",
    "        retriever_grader = grade_prompt | self.model | JsonOutputParser()\n",
    "\n",
    "        return retriever_grader\n",
    "    \n",
    "    \n",
    "    class GradeHallucinations(BaseModel):\n",
    "        \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
    "\n",
    "        binary_score: str = Field(\n",
    "            description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
    "        )\n",
    "\n",
    "    def create_hallucination_grader(self):\n",
    "        \"\"\"\n",
    "        Creates a hallucination grader that assesses whether an answer is grounded in/supported by a set of facts.\n",
    "\n",
    "        Returns:\n",
    "            A callable function that takes a generation (answer) and a list of documents (facts) as input and returns a JSON object with a binary score indicating whether the answer is grounded in/supported by the facts.\n",
    "        \"\"\"\n",
    "        # hallucination_prompt = PromptTemplate(\n",
    "        #     template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "        #     You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n \n",
    "        #     Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.\n",
    "        #     Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
    "        #     <|eot_id|>\n",
    "        #     <|start_header_id|>user<|end_header_id|>\n",
    "        #     Here are the facts:\n",
    "        #     \\n ------- \\n\n",
    "        #     {documents}\n",
    "        #     \\n ------- \\n\n",
    "        #     Here is the answer: {generation}\n",
    "        #     <|eot_id|>\n",
    "        #     <|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "        #     input_variables=[\"generation\", \"documents\"],\n",
    "        # )\n",
    "\n",
    "        system = \"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n \n",
    "                 Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.\n",
    "                 Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\"\"\"\n",
    "        hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", system),\n",
    "                (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        hallucination_grader = hallucination_prompt | self.model | JsonOutputParser()\n",
    "\n",
    "        return hallucination_grader\n",
    "\n",
    "    def answer_grader(self):\n",
    "        \"\"\"\n",
    "        Creates a code evaluator that assesses whether the generated code is correct and relevant to the given question.\n",
    "\n",
    "        Returns:\n",
    "            A callable function that takes a generation (code), a question, and a list of documents as input and returns a JSON object with a binary score and feedback.\n",
    "        \"\"\"\n",
    "        eval_template = PromptTemplate(\n",
    "            template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether an answer addresses / resolves a question \\n \n",
    "            Give a binary score 'yes' or 'no'. Yes' means that the answer resolves the question.\n",
    "            Provide a JSON response with the following keys:\n",
    "\n",
    "            'score': A binary score 'yes' or 'no' indicating whether the code is correct and relevant.\n",
    "            'feedback': A brief explanation of your evaluation, including any issues or improvements needed.\n",
    "\n",
    "            <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "            Here is the generated code:\n",
    "            \\n ------- \\n\n",
    "            {generation}\n",
    "            \\n ------- \\n\n",
    "            Here is the question: {question}\n",
    "            \\n ------- \\n\n",
    "            Here are the relevant documents: {documents}\n",
    "            <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "            input_variables=[\"generation\", \"question\", \"documents\"],\n",
    "        )\n",
    "\n",
    "        code_evaluator = eval_template | self.model | JsonOutputParser()\n",
    "\n",
    "        return code_evaluator\n",
    "\n",
    "    def create_question_rewriter(self):\n",
    "        \"\"\"\n",
    "        Creates a question rewriter chain that rewrites a given question to improve its clarity and relevance.\n",
    "\n",
    "        Returns:\n",
    "            A callable function that takes a question as input and returns the rewritten question as a string.\n",
    "        \"\"\"\n",
    "        system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n \n",
    "        for vectorstore retrieval. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
    "        re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", system),\n",
    "                (\n",
    "                    \"human\",\n",
    "                    \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        question_rewriter = re_write_prompt | self.model | StrOutputParser()\n",
    "\n",
    "        return question_rewriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 'yes'}\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the GraderUtils class\n",
    "grader = GraderUtils(llm)\n",
    "\n",
    "# Get the retrieval grader\n",
    "retrieval_grader = grader.create_retrieval_grader()\n",
    "\n",
    "# test it!\n",
    "doc_txt = docs[1].page_content\n",
    "\n",
    "# check with the grader\n",
    "print(retrieval_grader.invoke({\"question\": query,\"document\": doc_txt}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 'yes'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the hallucination grader\n",
    "hallucination_grader = grader.create_hallucination_grader()\n",
    "# test\n",
    "hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 'yes',\n",
       " 'feedback': 'The answer provides a brief explanation of SOLAS, including its purpose, key regulations, and the establishment of a safety management system. The explanation is accurate and relevant, citing specific documents and pages from the provided PDFs. However, the answer could be improved by providing more context and examples to illustrate the importance and application of SOLAS in real-world scenarios.'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the answer_grader\n",
    "answer_grader = grader.answer_grader()\n",
    "# test\n",
    "answer_grader.invoke({\"generation\": generation, \"question\": query, \"documents\": docs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Improved question: \\nWhat is the purpose and key components of the International Convention for the Safety of Life at Sea (SOLAS), and how does it impact maritime safety regulations?\\n\\nReasoning:\\nThe initial question is quite broad and lacks specificity. The improved question aims to:\\n\\n1. Clarify the intent: The improved question asks for a brief explanation of SOLAS, which is a more specific and focused query.\\n2. Provide context: The added phrase \"International Convention for the Safety of Life at Sea\" helps to establish the context and scope of the query.\\n3. Encourage more detailed information: The phrase \"key components\" and \"impact on maritime safety regulations\" suggests that the user is looking for a more in-depth explanation, which can lead to a more informative and relevant response.\\n\\nThis improved question is better suited for vectorstore retrieval, as it:\\n\\n1. Reduces ambiguity: The improved question is more specific and clear, reducing the likelihood of misinterpretation.\\n2. Encourages more targeted information: The improved question is more likely to elicit a response that provides relevant and useful information, rather than a generic or superficial answer.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the question rewriter\n",
    "question_rewriter = grader.create_question_rewriter()\n",
    "question_rewriter.invoke({\"question\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start the Graph\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "\n",
    "    question: str\n",
    "    generation: str\n",
    "    documents: str #List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "class GraphNodes:\n",
    "    def __init__(self, llm, retriever, retrieval_grader, hallucination_grader, code_evaluator, question_rewriter):\n",
    "        self.llm = llm\n",
    "        self.retriever = retriever\n",
    "        self.retrieval_grader = retrieval_grader\n",
    "        self.hallucination_grader = hallucination_grader\n",
    "        self.code_evaluator = code_evaluator\n",
    "        self.question_rewriter = question_rewriter\n",
    "        self.generate_chain = create_generate_chain(llm)\n",
    "\n",
    "    def retrieve(self, state):\n",
    "        \"\"\"\n",
    "        Retrieve documents\n",
    "\n",
    "        Args:\n",
    "            state (dict): The current graph state\n",
    "\n",
    "        Returns:\n",
    "            state (dict): New key added to state, documents, that contains retrieved documents\n",
    "        \"\"\"\n",
    "        print(\"---RETRIEVE---\")\n",
    "        question = state[\"question\"]\n",
    "\n",
    "        # Retrieval\n",
    "        documents = self.retriever.invoke(question)\n",
    "        return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "    def generate(self, state):\n",
    "        \"\"\"\n",
    "        Generate answer\n",
    "\n",
    "        Args:\n",
    "            state (dict): The current graph state\n",
    "\n",
    "        Returns:\n",
    "            state (dict): New key added to state, generation, that contains LLM generation\n",
    "        \"\"\"\n",
    "        print(\"---GENERATE---\")\n",
    "        question = state[\"question\"]\n",
    "        documents = state[\"documents\"]\n",
    "\n",
    "        # RAG generation\n",
    "        generation = self.generate_chain.invoke({\"context\": documents, \"question\": question})\n",
    "        return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "\n",
    "    def grade_documents(self, state):\n",
    "        \"\"\"\n",
    "        Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "        Args:\n",
    "            state (dict): The current graph state\n",
    "\n",
    "        Returns:\n",
    "            state (dict): Updates documents key with only filtered relevant documents\n",
    "        \"\"\"\n",
    "        print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "        question = state[\"question\"]\n",
    "        documents = state[\"documents\"]\n",
    "\n",
    "        # score each doc\n",
    "        filtered_docs = []\n",
    "\n",
    "        for d in documents:\n",
    "            score = self.retrieval_grader.invoke({\"question\": question, \"document\": d.page_content})\n",
    "            grade = score[\"score\"]\n",
    "            if grade == \"yes\":\n",
    "                print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "                filtered_docs.append(d)\n",
    "            else:\n",
    "                print(\"---GRADE: DOCUMENT IR-RELEVANT---\")\n",
    "                continue\n",
    "\n",
    "        return {\"documents\": filtered_docs, \"question\": question}\n",
    "\n",
    "    def transform_query(self, state):\n",
    "        \"\"\"\n",
    "        Transform the query to produce a better question.\n",
    "\n",
    "        Args:\n",
    "            state (dict): The current graph state\n",
    "\n",
    "        Returns:\n",
    "            state (dict): Updates question key with a re-phrased question\n",
    "        \"\"\"\n",
    "        print(\"---TRANSFORM QUERY---\")\n",
    "        question = state[\"question\"]\n",
    "        documents = state[\"documents\"]\n",
    "\n",
    "        # Re-write question\n",
    "        better_question = self.question_rewriter.invoke({\"question\": question})\n",
    "        return {\"documents\": documents, \"question\": better_question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeGraph:\n",
    "    def __init__(self, hallucination_grader, code_evaluator):\n",
    "        self.hallucination_grader = hallucination_grader\n",
    "        self.code_evaluator = code_evaluator\n",
    "\n",
    "    def decide_to_generate(self, state):\n",
    "        \"\"\"\n",
    "        Determines whether to generate an answer, or re-generate a question.\n",
    "\n",
    "        Args:\n",
    "            state (dict): The current graph state\n",
    "\n",
    "        Returns:\n",
    "            str: Binary decision for next node to call\n",
    "        \"\"\"\n",
    "        print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "        question = state[\"question\"]\n",
    "        filtered_documents = state[\"documents\"]\n",
    "\n",
    "        if not filtered_documents:\n",
    "            # All documents have been filtered check_relevance\n",
    "            # We will re-generate a new query\n",
    "            print(\"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\")\n",
    "            return \"transform_query\"  # \"retrieve_from_community_page\", \"transform_query\"\n",
    "        else:\n",
    "            # We have relevant documents, so generate answer\n",
    "            print(\"---DECISION: GENERATE---\")\n",
    "            return \"generate\"\n",
    "\n",
    "    def grade_generation_v_documents_and_question(self, state):\n",
    "        \"\"\"\n",
    "        Determines whether the generation is grounded in the document and answers question.\n",
    "\n",
    "        Args:\n",
    "            state (dict): The current graph state\n",
    "\n",
    "        Returns:\n",
    "            str: Decision for next node to call\n",
    "        \"\"\"\n",
    "        print(\"---CHECK HALLUCINATIONS---\")\n",
    "        question = state[\"question\"]\n",
    "        documents = state[\"documents\"]\n",
    "        generation = state[\"generation\"]\n",
    "\n",
    "        score = self.hallucination_grader.invoke({\"documents\": documents, \"generation\": generation})\n",
    "        grade = score[\"score\"]\n",
    "\n",
    "        # Check hallucination\n",
    "        if grade == \"yes\":\n",
    "            print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "            # Check question-answering\n",
    "            print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "            score = self.code_evaluator.invoke({\"question\": question, \"generation\": generation, \"documents\": documents})\n",
    "            grade = score[\"score\"]\n",
    "            if grade == \"yes\":\n",
    "                print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "                return \"useful\"\n",
    "            else:\n",
    "                print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "                return \"not useful\"\n",
    "        else:\n",
    "            print(\"---DECISION: GENERATIONS ARE HALLUCINATED, RE-TRY---\")\n",
    "            return \"not supported\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiating the Graph\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Create an instance of the GraphNodes class\n",
    "graph_nodes = GraphNodes(llm, retriever, retrieval_grader, hallucination_grader, answer_grader, question_rewriter)\n",
    "\n",
    "# Create an instance of the EdgeGraph class\n",
    "edge_graph = EdgeGraph(hallucination_grader, answer_grader)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"retrieve\", graph_nodes.retrieve) # retrieve documents\n",
    "workflow.add_node(\"grade_documents\", graph_nodes.grade_documents)  # grade documents\n",
    "workflow.add_node(\"generate\", graph_nodes.generate) # generate answers\n",
    "workflow.add_node(\"transform_query\", graph_nodes.transform_query)  # transform_query\n",
    "\n",
    "# Build graph\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    edge_graph.decide_to_generate,\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\", # \"transform_query\": \"transform_query\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"transform_query\", \"retrieve\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    edge_graph.grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        \"not supported\": \"generate\",\n",
    "        \"useful\": END,\n",
    "        \"not useful\": \"transform_query\", # \"transform_query\"\n",
    "    },\n",
    ")\n",
    "\n",
    "# Compile\n",
    "network = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVE---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: GENERATE---\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"question\": \"let me know brief explanation about SOLAS?\"}\n",
    "\n",
    "response = network.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, SOLAS (International Convention for the Safety of Life at Sea, 1974) is a maritime convention that aims to ensure the safety of life at sea. The convention requires ships to be designed, constructed, and equipped to prevent accidents and minimize the risk of loss of life.\n",
      "\n",
      "According to the context, SOLAS has undergone several amendments, including the addition of new regulations 23-2 and 42-1 to Chapter II-1 of the SOLAS Convention. Regulation 23-2 deals with the integrity of the hull and superstructure, damage prevention, and control, and requires indicators to be provided on the navigating bridge for all doors that, if left open, could lead to major flooding.\n",
      "\n",
      "SOLAS also requires the establishment of a safety management system (SMS) by shipowners or operators, which should be designed to ensure compliance with all mandatory regulations and take into account codes, guidelines, and standards recommended by IMO and others.\n",
      "\n",
      "In summary, SOLAS is a maritime convention that aims to ensure the safety of life at sea by setting standards for ship design, construction, and operation, and requires the establishment of a safety management system to prevent accidents and minimize the risk of loss of life.\n"
     ]
    }
   ],
   "source": [
    "print(response['generation'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
